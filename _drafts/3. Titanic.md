---
title: ' Titanic '
author: ernest
date: 2019-03-10 16:20:02 -05:00
last_modified_at: 2023-11-30
categories: [ Work ]
pin:     # true
math: true
mermaid: true
tags:   # or [typography, tag-01, tag-02, etc.]
  - classification
  # - tamplate-tag-2
  # - template-tag-3

image: 
  path: /assets/articles/cover-austin-chan_web.png
  # image: /assets/sample/coming-soon.png
  alt: Photo by Austin Chan on Unplash.

---


> All content provided is for informational purposes only and shown case studies examples for open source data resources. The articles and posts on this website are my own way on seen opportunities and problem-solving but don’t necessarily represent the positions, strategies, or opinions of my employer or its subsidiaries. I make no representations as to the accuracy or completeness of any information found here or by following any links. I will not be liable for any errors or omissions in this information nor for the availability of this information. I will not be liable for any losses, injuries, or damages from the display or use of this information.
{: .prompt-info }



[Codebook](/assets/docs/paper1.pdf){:target="_blank"}


## Section 1
  This is 1

## Section 2

  This is 2

### Sub-section 1

  This is 3


## Section 3
  
  This is 4

### Sub-section 2

  This is 5





## Summary


This is a sample blog post. Lorem ipsum I can't remember the rest[^1] of lorem ipsum and don't have an internet connection right now. Testing testing testing this blog post. Blog posts are cool. This is a sample blog post. Lorem ipsum I can't remember the rest of lorem ipsum and don't have an internet connection right now. Testing testing testing this blog post. Blog posts are cool. This is a sample blog post. Lorem ipsum I can't remember the rest of lorem ipsum and don't have an internet connection right now. Testing testing testing this blog post. Blog posts are cool. This is a sample blog post. Lorem ipsum I can't remember the rest of lorem ipsum and don't have an internet connection right now. Testing testing testing this blog post. Blog posts are cool. This is a sample blog post. Lorem ipsum I can't remember the rest of lorem ipsum and don't have an internet connection right now. Testing testing testing this blog post. Blog posts are cool. 











## NOTES BELOW - delete this 

Classification with Neural Nets Demonstrated with the
Titanic Dataset
We will briefly build a neural network for classification in this example so that
we can compare to other classifications’ attempts in the next two chapters. In
order to do that, we will create a partition variable again. The variable is already
created in the Titanic_Results.sav dataset.
This time a 70% Train/30% Test partition will be used:
COMPUTE Train_Test=rv.bernoulli(0.7).
The Dependent variable is Survived, and there will be four predictors. Pclass
(passenger class) and Sex are Factors and Age and Parch (which refers to number
of parents and children aboard) are covariates. In theory, the neural net
could handle the entire dataset, but neural nets tend to become overly complex
and we won’t have the opportunity in this section to do a proper job of feature
selection. One should be a bit cautious about giving neural net variables
that have a very weak relationship to the Dependent as it will always use all
variables. Weak predictors will be not be given large weights, but they will
make the model more complex nonetheless. So to make it simple in this case,
the variables chosen are variables known to have an ability to predict Survived
(Figure 13-25).
Note that since the output variable is binary there are two nodes in the output
layer as shown in Figure 13-26.



We have much more to say about the results in Chapter 15. The accuracy is
OK, but not stellar (Figure 13-27). Although the accuracy degrades on the Testing
partition, the amount that the accuracy has dropped is within acceptable limits,
but just barely. It has dropped from 82.0% to 77%. A common rule of thumb is
that a drop of greater than 5% would indicate that it is unstable. It does a better
join with non-survivors (83.2%) than survivors (70.1%). This might tempt us to
balance the data (as discussed in the previous chapter), but balancing in SPSS
Statistics would be a bit time consuming and a bit of a challenge. (However,
seemingly difficult steps like this can be much easier with a good extension
command. We discuss this in Chapter 18.) This result is acceptable enough to
represent neural net in the “competition” in Chapter 15. If neural net were to
win, we might want to revisit the model and see if we couldn’t improve both
stability and accuracy a bit. Nonetheless, we will give it one more try




####

---
title: ' Titanic '
author: ernest
date: 2019-03-10 16:20:02 -05:00
last_modified_at: 2023-11-30
categories: [ Work ]
pin:     # true
math: true
mermaid: true
tags:   # or [typography, tag-01, tag-02, etc.]
  - classification
  # - tamplate-tag-2
  # - template-tag-3

image: 
  path: /assets/articles/cover-austin-chan_web.png
  # image: /assets/sample/coming-soon.png
  alt: Photo by Austin Chan on Unplash.

---


> All content provided is for informational purposes only and shown case studies examples for open source data resources. The articles and posts on this website are my own way on seen opportunities and problem-solving but don’t necessarily represent the positions, strategies, or opinions of my employer or its subsidiaries. I make no representations as to the accuracy or completeness of any information found here or by following any links. I will not be liable for any errors or omissions in this information nor for the availability of this information. I will not be liable for any losses, injuries, or damages from the display or use of this information.
{: .prompt-info }



[Codebook](/assets/docs/paper1.pdf){:target="_blank"}

My github repos with additional free and paid resources:

ML Process: https://github.com/PlayingNumbers/ML_Process_Course
ML ALgorithms: https://github.com/PlayingNumbers/ML_Algorithms_Course


(1) Exploration of the dataset
(2) 



This video covers
- Project Planning 
  - understanding the nature of the data
  - Histograms and boxplots
  - value counts
  - Correlation between the metrics
  - Exploration interesting themes
    - Wealthy survive?
    - By location
    - Age scatterplots with ticket price
    - Young and wealthy variable?
    - Total spent?
  - 
- Data exploration 
  

- Data Visualization (light)
- Replacing null values 
- Feature engineering 
- Data Cleaning 
- Model Production
- Model Tuning
- Kaggle model submission 




## Summary

  Story behind the dataset

## Techniques used

  keywords Statistical Descriptive

## Task 

  Description

## Data Description

  Description dataset & variables

## Analysis
  
  Analysis

## Summary Statistical Insights

  Description

## Managerial Implications
  
  Description

## Keywords










Titanic Survival Prediction - Machine Learning Project

https://www.youtube.com/watch?v=fATVVQfFyU0

Kaggle Challenge: https://www.kaggle.com/c/titanic


The Challenge
The sinking of the Titanic is one of the most infamous shipwrecks in history.

On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.

While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.

In this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc).

Goal
It is your job to predict if a passenger survived the sinking of the Titanic or not.
For each in the test set, you must predict a 0 or 1 value for the variable.

Metric
Your score is the percentage of passengers you correctly predict. This is known as accuracy.

Submission File Format
You should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.
The file should have exactly 2 columns:

PassengerId (sorted in any order)
Survived (contains your binary predictions: 1 for survived, 0 for deceased)




Problem definition and metrics
The problem is a binary class classification problem. We can use binary crossentropy or logistic loss as the loss function and any metric like accuracy or/and ROC AUC score as a metric to evaluate the results.



https://medium.com/analytics-vidhya/titanic-dataset-analysis-80-accuracy-9480cf3db538


Question 1: How do the features ‘Age’, ‘Sex’, ‘Fare’, ‘Embarked’ affect the chance of a passenger’s survival?

Question 2: How to determine other features that affected a passenger’s chance of survival?

Feature Engineering
Three kinds of visualizations used (primarily box plots and density plots):

Boxplots : To tell us about the range of distribution (or, 1st quartile, median, 3rd quartile) of the feature for each output class and give us an idea about the outliers in the data
Density plots : To tell us about the distribution and more about the shape of the distribution (resembling normal or any other disb) of the feature
Stacked countplots : Tells us more about count of each category of the feature with information about the percentage belonging to which output class


Model selection
We experiment with the simple binary classification models like Logistic Regression, SVM, KNN, followed by decision tree based classifiers, like Random Forest, XGBoost.




## NOTES BELOW - delete this 

Classification with Neural Nets Demonstrated with the
Titanic Dataset
We will briefly build a neural network for classification in this example so that
we can compare to other classifications’ attempts in the next two chapters. In
order to do that, we will create a partition variable again. The variable is already
created in the Titanic_Results.sav dataset.
This time a 70% Train/30% Test partition will be used:
COMPUTE Train_Test=rv.bernoulli(0.7).
The Dependent variable is Survived, and there will be four predictors. Pclass
(passenger class) and Sex are Factors and Age and Parch (which refers to number
of parents and children aboard) are covariates. In theory, the neural net
could handle the entire dataset, but neural nets tend to become overly complex
and we won’t have the opportunity in this section to do a proper job of feature
selection. One should be a bit cautious about giving neural net variables
that have a very weak relationship to the Dependent as it will always use all
variables. Weak predictors will be not be given large weights, but they will
make the model more complex nonetheless. So to make it simple in this case,
the variables chosen are variables known to have an ability to predict Survived
(Figure 13-25).
Note that since the output variable is binary there are two nodes in the output
layer as shown in Figure 13-26.



We have much more to say about the results in Chapter 15. The accuracy is
OK, but not stellar (Figure 13-27). Although the accuracy degrades on the Testing
partition, the amount that the accuracy has dropped is within acceptable limits,
but just barely. It has dropped from 82.0% to 77%. A common rule of thumb is
that a drop of greater than 5% would indicate that it is unstable. It does a better
join with non-survivors (83.2%) than survivors (70.1%). This might tempt us to
balance the data (as discussed in the previous chapter), but balancing in SPSS
Statistics would be a bit time consuming and a bit of a challenge. (However,
seemingly difficult steps like this can be much easier with a good extension
command. We discuss this in Chapter 18.) This result is acceptable enough to
represent neural net in the “competition” in Chapter 15. If neural net were to
win, we might want to revisit the model and see if we couldn’t improve both
stability and accuracy a bit. Nonetheless, we will give it one more try


Table of Contents
About the dataset :
Missing values?
EDA
Data preprocessing
Baseline Model
Model 1: Logistic Regression, GLM
Model 2 : Generative Additive Models
Model 3: Ensembles
Voting Classifier
Test predictions
Results:









#### Reference

- https://www.encyclopedia-titanica.org/titanic-tickets/

- https://www.kaggle.com/code/aish0997/titanic-dataset-80-accuracy/notebook




## Footnote

[^1]: The footnote source
[^2]: The 2nd footnote source








####





## Footnote

[^1]: The footnote source
[^2]: The 2nd footnote source





